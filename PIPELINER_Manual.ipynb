{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINER: A Versatile RNA-Seq Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High throughput sequencing (HTS) technology has become imperative for many projects in the field of molecular biology, oncology, evolutionary biology and metagenomics. It is now possible to obtain millions of sequencing reads in a single experiment in a cost effective manner. However, the analysis of HTS requires heavy utilization of computational techniques, with various processing steps from read quality assessment to quantification. In addition to the massive size, the heterogeneous nature of the datasets involved with the analysis has posed major challenges including the urgent need to develop an efficient and reproducible framework that allows computational experts and wet-lab scientists to build, run and analyze NGS data in a comprehensive manner. We created ‘PIPELINER’ - a framework that is efficient for the user and can generate flexible and modular workflows for quality assessment and processing of HTS data. PIPELINER is based on [Nextflow](https://www.nextflow.io), a portable, scalable, parallelizable framework that enables our pipelines to have language and platform independence, implicit parallelism, and automatic failure recovery. Additionally, it comes with an anaconda virtual environment which allows for a pre-compilation of all the tools used for HTS data analysis. This makes the deployment process and execution platform-independent and less cumbersome. As a proof of concept, we developed RNA-Seq pipeline for processing of bulk RNA-sequencing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIPELINER consists of a main nextflow script which is parameterized using a configuration file. The read file information is extracted from a csv file containing the samples and paths to their corresponding reads. There is then a check for index files for read mapping and generation of indexes (if not specified earlier) based on the aligner option selected by the user.  PIPELINER involves the following five key processes:\n",
    "- **Read quality assessment and trimming:** Under this process the input reads are checked for their quality using FastQC. The adaptor sequences  in the input reads are then trimmed using Trim-galore. \n",
    "- **Alignment:** The processed reads are then mapped to their index using STAR or Tophat alignment tools. However,  the user can bypass this step using kallisto which is a pseudo aligner. RseQC was used to generate statistics for the resulting bam files.\n",
    "- **Quantification:** The reads aligned using STAR or Tophat are assembled and quantified using StringTie (FPKM metric). While the reads that are sent to kallisto are quantified using Transcripts per million (TPM) metric.\n",
    "- **Report generation**: The results from the above processes are bundled into a single report using MultiQC for better visualization and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeliner requires Nextflow and Java 7 or greater for implementation. All other tools for implementation are wrapped in an environment described below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Download Nextflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure Java 7 or 8 is installed and install Nextflow in directory you plan to work in"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "java -version\n",
    "curl -fsSL get.nextflow.io | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Download Conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conda is available through [Anaconda](https://www.continuum.io/downloads) and [Miniconda](https://conda.io/miniconda.html) for any platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using a module system such as the shared computing cluster (SCC) at Boston University you can load a preinstalled version:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "module purge\n",
    "module load anaconda2/4.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create Conda Environment (rna_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download rna_env file from Pipeliner repository in anaconda cloud"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda env create pipeliner/rna_env\n",
    "source activate rna_env\n",
    "\n",
    "or \n",
    "\n",
    "conda create \\\n",
    "  -p ./rna_env \\\n",
    "  -c https://conda.anaconda.org/Pipeliner \\\n",
    "  --yes \\\n",
    "  hydra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an option to create your own conda environment and install each tool separately from PIPELINER anaconda repository (ex: bowtie2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda create -n rna_env python=2 anaconda --yes\n",
    "\n",
    "conda install -c pipeliner bowtie2=2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running PIPELINER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Activate the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source activate rna_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeliner consists of a main nextflow script parametrized using a configuration file. The example *Gallus gallus* (chicken) dataset is all within the ggal folder. All files necessary to run this example is in the folder \"Gallus_Example\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example configuration file for *Gallus gallus* data. The configuration file includes all parameters necessary to run the pipeline including  parameters to direct the path of files and results, as well as selecting specific tools and processes to run. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params #set parameters\n",
    "{\n",
    "  genomes #set paths and specific conditions to run the pipeline\n",
    "    {\n",
    "    'ggal'\n",
    "        {\n",
    "\n",
    "        fasta = '~/Ggal_Example/ggal/genome.index.fa' #path to index file\n",
    "        gtf   ='~/Ggal_Example/ggal/genome.bed.gff'   #path to gtf file\n",
    "        sample_reads_file = '~/Ggal_Example/ggal_alpha.csv' #set path to sample reads file\n",
    "        paired = true #Specifies if data is paired-end\n",
    "//     \tstar = '~/star/ref_test/star' #path to reference file\n",
    "//\t\tkallistoindex = '~/kallisto/transcriptome.index' #path to kallisto reference file\n",
    "        outdir = '~/results/ggal_results_test' #set path for results\n",
    "        project = 'pulmseq' #if working in a shared computing cluster, state project you are working in\n",
    "        transcriptome= '~/Ggal_Example/ggal/Ggal_Transcriptome.fa' #path to transcriptome file \n",
    "//     \tbowtie = '/reference_genome/bowtie' #path to bowtie reference \n",
    "        aligner = 'star' #set aligner option (i.e. in this case STAR)\n",
    "        bed = '~/Ggal_Example/ggal/ggal_refseq.bed' #path to ggal bed file\n",
    "//      refgenome ='star/ref_test/star' #path to reference genome for star\n",
    "        email = 'user@email.com' #set email address for notifications and report\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the appropriate paths and tools have been set in the configuration file, you can run the pipeline with the configuration file:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nextflow main.nf -c ./Gallus_Example/config_ggal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local executor is used by default. However, PIPELINER can be run using a SGE executor with cluster options such as allocation of CPUs for each process specified in the main pipeline script. The pipeline is executed through a cluster facility by submitting the job using the qsub command. Each process is treated as a separate job that is submitted to the cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an issue arises and pipline stops running, you can check the nextflow log file that is created during each run to determine the problem. Note: A new log file is created after each run and the most recent log file is not numbered. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vim .nextflow.log #recent log file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have resolved the issues, the pipeline can be resumed using the same command to run the pipeline with -resume:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nextflow main.nf -c ./Gallus_Example/config_ggal -resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIPELINER includes helpful features including a report sent to your email that demonstrates how long the pipeline including each process took to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include an example report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
